{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AAydpdtiaCyi"
   },
   "outputs": [],
   "source": [
    "!pip install mrjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngecK352bMi5"
   },
   "source": [
    "# Python MRJob Package\n",
    "- https://mrjob.readthedocs.io/en/latest/\n",
    "\n",
    "`mrjob` is the easiest route to writing Python programs that run on Hadoop. If you use mrjob, youâ€™ll be able to test your code locally without installing Hadoop or run it on a cluster of your choice.\n",
    "\n",
    "# MRJob Examples\n",
    "- https://github.com/Yelp/mrjob/tree/master/mrjob/examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cl9gVrHpcuod"
   },
   "outputs": [],
   "source": [
    "%%file wc.py\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        yield \"chars\", len(line)\n",
    "        yield \"words\", len(line.split())\n",
    "        yield \"lines\", 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SMSvh4NcfoXm"
   },
   "source": [
    "# Text - War And Peace\n",
    "https://www.gutenberg.org/ebooks/2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uZohxu4ebEH"
   },
   "outputs": [],
   "source": [
    "!curl https://www.gutenberg.org/files/2600/2600-0.txt -o warpeace.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOK_e_AUeLtM"
   },
   "outputs": [],
   "source": [
    "import wc\n",
    "\n",
    "mr_job = wc.MRWordFrequencyCount(args=['warpeace.txt'])\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    for key, value in mr_job.parse_output(runner.cat_output()):\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SMSvh4NcfoXm"
   },
   "source": [
    "# Temperature data\n",
    "https://github.com/PacktPublishing/Frank-Kanes-Taming-Big-Data-with-Apache-Spark-and-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/PacktPublishing/Frank-Kanes-Taming-Big-Data-with-Apache-Spark-and-Python/master/1800.csv -o 1800.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaEO5AB3a_R0"
   },
   "outputs": [],
   "source": [
    "!tail -n 10 1800.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4VL4xqwhpFk"
   },
   "outputs": [],
   "source": [
    "%%file max_temp.py\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRMaxTemperature(MRJob):\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_fahrenheit(cels):\n",
    "        celsius = float(cels) / 10.0\n",
    "        fahrenheit = celsius * 1.8 + 32.0\n",
    "        return fahrenheit\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        (location, date, type, data, x, y, z, w) = line.split(',')\n",
    "        if (type == 'TMAX'):\n",
    "            temperature = self.to_fahrenheit(data)\n",
    "            yield location, temperature\n",
    "\n",
    "    def reducer(self, location, temps):\n",
    "        yield location, max(temps)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMaxTemperature.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrj9J1kxhs5O"
   },
   "outputs": [],
   "source": [
    "import max_temp\n",
    "\n",
    "mr_job = max_temp.MRMaxTemperature(args=['1800.csv'])\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    for key, value in mr_job.parse_output(runner.cat_output()):\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5qAEf5GiBjX"
   },
   "source": [
    "# Let's do it on EMR\n",
    "https://github.com/Yelp/mrjob/blob/master/docs/guides/emr-quickstart.rst"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data 603 Lecture 3 - Map Reduce.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
