{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "445dd548-b84b-4343-819f-b11e53b94530",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "# Spark Data Sources\n",
    "\n",
    "This notebook shows how to use Spark Data Sources Interface API to read file formats:\n",
    " * Parquet\n",
    " * JSON\n",
    " * CSV\n",
    " * Avro\n",
    " * ORC\n",
    " * Image\n",
    " * Binary\n",
    "\n",
    "A full list of DataSource methods is available [here](https://docs.databricks.com/spark/latest/data-sources/index.html#id1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "feae3eab-a04b-4aa2-9ed4-e4c32db53081",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Define paths for the various data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9ba911fe-9337-4417-9d27-3dd1f3c206fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parquet_file = \"/databricks-datasets/learning-spark-v2/flights/summary-data/parquet/2010-summary.parquet\"\n",
    "json_file = \"/databricks-datasets/learning-spark-v2/flights/summary-data/json/*\"\n",
    "csv_file = \"/databricks-datasets/learning-spark-v2/flights/summary-data/csv/*\"\n",
    "orc_file = \"/databricks-datasets/learning-spark-v2/flights/summary-data/orc/*\"\n",
    "avro_file = \"/databricks-datasets/learning-spark-v2/flights/summary-data/avro/*\"\n",
    "schema = \"DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count INT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bfb593c2-e1be-47e9-821f-518ca9720a2c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Parquet Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1e1c644-f73a-4532-81a9-a5f6c4aaa27d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (spark\n",
    "      .read\n",
    "      .format(\"parquet\")\n",
    "      .option(\"path\", parquet_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e55855e-8b89-45f7-8487-f88bf4aa16f5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Another way to read this same data using a variation of this API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3e042e91-c6cc-446a-a8b5-cdd5cfd6e65d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = spark.read.parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8b7070e0-cf9c-4763-b58d-7c218594172f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "721034d4-bf29-47e9-9b2e-ce0526170ffd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use SQL\n",
    "\n",
    "This will create an _unmanaged_ temporary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d0a685e8-9815-4f70-bc0c-1d404786c5d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl\n",
    "    USING parquet\n",
    "    OPTIONS (\n",
    "      path \"/databricks-datasets/definitive-guide/data/flight-data/parquet/2010-summary.parquet\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8b231f47-7c57-4326-ac65-8810c63e88c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Use SQL to query the table\n",
    "\n",
    "The outcome should be the same as one read into the DataFrame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e08d62f-a09b-4980-8f26-437629539d10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6a43f650-a5ef-449b-8c76-b40341ec4437",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## JSON Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "206dad1b-64a3-4b31-b77b-82d48b7e1ba2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").option(\"path\", json_file).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2db970aa-4ffd-48f5-a829-4f8328548d1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "023c3fd5-028d-4571-879e-008db36c7e17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = spark.read.json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c1cdac5c-562c-43a1-8c6b-db3343cb21ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "29ba3ea9-27fc-4fee-9787-c75592c9c7c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use SQL\n",
    "\n",
    "This will create an _unmanaged_ temporary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2a87271d-08b7-408c-839b-35d678d14eff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl\n",
    "    USING json\n",
    "    OPTIONS (\n",
    "      path \"/databricks-datasets/learning-spark-v2/flights/summary-data/json/*\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aa0cd29f-bc94-4fdd-b5ef-b8dd3eb6632d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Use SQL to query the table\n",
    "\n",
    "The outcome should be the same as one read into the DataFrame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4a8415dd-9569-4709-a88b-9a087645071b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2487b993-a8f4-4c0f-a24c-085394be3b5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## CSV Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "235e4586-cd30-4de4-a9ab-470803a40462",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (spark\n",
    "      .read\n",
    "\t .format(\"csv\")\n",
    "\t .option(\"header\", \"true\")\n",
    "\t .schema(schema)\n",
    "\t .option(\"mode\", \"FAILFAST\")  # exit if any errors\n",
    "\t .option(\"nullValue\", \"\")\t  # replace any null data field with “”\n",
    "\t .option(\"path\", csv_file)\n",
    "\t .load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "62e4a622-e299-4ac6-b9e9-3a47d220a94b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9d4bc3b6-d464-492c-8426-a0e6b461f9d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(df.write.format(\"parquet\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"path\", \"/tmp/data/parquet/df_parquet\")\n",
    "  .option(\"compression\", \"snappy\")\n",
    "  .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "133fcbf4-b052-4ea9-a5cb-9ee746560ead",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /tmp/data/parquet/df_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df9c9a1e-660b-4d4d-b6f0-aa63c4596c05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = (spark\n",
    "       .read\n",
    "       .option(\"header\", \"true\")\n",
    "       .option(\"mode\", \"FAILFAST\")\t # exit if any errors\n",
    "       .option(\"nullValue\", \"\")\n",
    "       .schema(schema)\n",
    "       .csv(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7f3c36d-57a9-4d65-bfaf-e71bd2c6329c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e36c9f3c-11bb-4746-bd73-45ca866d49d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use SQL\n",
    "\n",
    "This will create an _unmanaged_ temporary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f3608b0d-dc32-4c6a-84c1-d012cadd73c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl\n",
    "    USING csv\n",
    "    OPTIONS (\n",
    "      path \"/databricks-datasets/learning-spark-v2/flights/summary-data/csv/*\",\n",
    "      header \"true\",\n",
    "      inferSchema \"true\",\n",
    "      mode \"FAILFAST\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "95fb3584-0b22-4398-84fd-0a6de84dbf22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Use SQL to query the table\n",
    "\n",
    "The outcome should be the same as one read into the DataFrame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6d615327-6606-4471-8a55-6ff4e917eef8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "83fd78b2-2181-4e31-a7ba-eaf4f9e281a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ORC Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "45328661-83d8-4dd4-9c38-7d30da4c72a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "      .format(\"orc\")\n",
    "      .option(\"path\", orc_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b1a41e8d-3920-4d53-a93d-e25bfa8d9485",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7093b190-25ba-4095-94e1-f7b8bcb7008e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use SQL\n",
    "\n",
    "This will create an _unmanaged_ temporary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "74498126-17cb-4cce-b769-8f1dae28f79c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl\n",
    "    USING orc\n",
    "    OPTIONS (\n",
    "      path \"/databricks-datasets/learning-spark-v2/flights/summary-data/orc/*\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8f395d8d-2196-4da5-86b9-1f89cbab39e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Use SQL to query the table\n",
    "\n",
    "The outcome should be the same as one read into the DataFrame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bc7a0452-8b8a-4001-aa55-d45213939abd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cdfdf544-c9cf-48ad-bb3c-c9dd3ac90387",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Avro Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7bdafc0-9117-4947-bf02-38172ffce996",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "      .format(\"avro\")\n",
    "      .option(\"path\", avro_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2263c27-6989-4f0a-bc6e-d8bc3c678239",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8ece2fc2-b64c-4b6a-aa78-7cee06d560ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use SQL\n",
    "\n",
    "This will create an _unmanaged_ temporary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8305769e-8ea6-4406-8927-91a7adebb057",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl\n",
    "    USING avro\n",
    "    OPTIONS (\n",
    "      path \"/databricks-datasets/learning-spark-v2/flights/summary-data/avro/*\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0c9c29ed-646f-4fef-bcc0-fbd100d2e718",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Use SQL to query the table\n",
    "\n",
    "The outcome should be the same as the one read into the DataFrame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "18a2779e-c177-46f1-b5f0-91677ea9ccad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "848dbcbd-abd3-445c-95eb-032af261ed76",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c38dd396-38e0-441e-8528-b3cd9d5f6152",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import image\n",
    "\n",
    "image_dir = \"/databricks-datasets/cctvVideos/train_images/\"\n",
    "images_df = spark.read.format(\"image\").load(image_dir)\n",
    "images_df.printSchema()\n",
    "\n",
    "images_df.select(\"image.height\", \"image.width\", \"image.nChannels\", \"image.mode\", \"label\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e46f914e-570b-42bf-8353-560a2e1012ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5bb932d0-fbba-4692-82cc-5ba07ab5cca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = \"/databricks-datasets/learning-spark-v2/cctvVideos/train_images/\"\n",
    "binary_files_df = (spark.read.format(\"binaryFile\")\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\")\n",
    "  .load(path))\n",
    "\n",
    "binary_files_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dd844ac4-da62-476f-bd6f-edf005204309",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To ignore any partitioning data discovery in a directory, you can set the `recursiveFileLookup` to `true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5093c9ce-c258-4b36-8451-35880b128441",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "binary_files_df = (spark.read.format(\"binaryFile\")\n",
    "   .option(\"pathGlobFilter\", \"*.jpg\")\n",
    "   .option(\"recursiveFileLookup\", \"true\")\n",
    "   .load(path))\n",
    "binary_files_df.show(5)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "4-2 Spark Data Sources",
   "notebookOrigID": 1711869132946975,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
